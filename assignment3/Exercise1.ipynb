{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 -- The Dataset\n",
    "\n",
    "The PTB Dataset is a collection of text snippets of stories from the Wall Street Journal. \n",
    "The data set divided into 3 datasets for training, validation and testing, respectively.\n",
    "In this exercise we prepare the data for neural network training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "We have downloaded the PTB training set from https://github.com/tomsercu/lstm/tree/master/data and put the files `train.txt`, `test.txt` and `valid.txt` into the subfolder `ptb_data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some sample phrases\n",
    "\n",
    "Let's print some examples of phrases, which occur in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 7:\n",
      "\" although preliminary findings were reported more than a year ago the latest results appear in today 's new england journal of medicine a forum likely to bring new attention to the problem \n",
      "\"\n",
      "\n",
      "Line 34:\n",
      "\" yields on money-market mutual funds continued to slide amid signs that portfolio managers expect further declines in interest rates \n",
      "\"\n",
      "\n",
      "Line 67:\n",
      "\" in the new position he will oversee mazda 's u.s. sales service parts and marketing operations \n",
      "\"\n",
      "\n",
      "Line 93:\n",
      "\" south korea 's economic boom which began in N stopped this year because of prolonged labor disputes trade conflicts and sluggish exports \n",
      "\"\n",
      "\n",
      "Line 114:\n",
      "\" new england electric system bowed out of the bidding for public service co. of new hampshire saying that the risks were too high and the potential <unk> too far in the future to justify a higher offer \n",
      "\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_lines = (7, 34, 67, 93, 114)      # randomly chosen integers\n",
    "with open('ptb_data/train.txt') as fh:\n",
    "    for il, line in enumerate(fh):\n",
    "        if il in print_lines:\n",
    "            print('Line %i:\\n\"%s\"\\n' %(il, line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the text has been proprocessed as\n",
    "- ... it contains the special term `<unk>` in place of rare words that do not occur frequently in the dataset\n",
    "- ... there is no punctuation (exception in abbreviations)\n",
    "- ... words are in lower case\n",
    "- ... numbers have been replaced by \"N\"\n",
    "- ... spaces have been included before some terms such as \"’ll\", \"’s\", \"n’t\"\n",
    "Furthermore we can see that each line contains still the newline character `\\n` and also an additional space in the front."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding `<eos>`\n",
    "\n",
    "In order to represent the text as arrays, we need to add one further preprocessing step: each newline character should be replaced with the special sequence `<eos>`. We do this for our example sentences below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 7:\n",
      "\" although preliminary findings were reported more than a year ago the latest results appear in today 's new england journal of medicine a forum likely to bring new attention to the problem <eos>\"\n",
      "\n",
      "Line 34:\n",
      "\" yields on money-market mutual funds continued to slide amid signs that portfolio managers expect further declines in interest rates <eos>\"\n",
      "\n",
      "Line 67:\n",
      "\" in the new position he will oversee mazda 's u.s. sales service parts and marketing operations <eos>\"\n",
      "\n",
      "Line 93:\n",
      "\" south korea 's economic boom which began in N stopped this year because of prolonged labor disputes trade conflicts and sluggish exports <eos>\"\n",
      "\n",
      "Line 114:\n",
      "\" new england electric system bowed out of the bidding for public service co. of new hampshire saying that the risks were too high and the potential <unk> too far in the future to justify a higher offer <eos>\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_lines = (7, 34, 67, 93, 114)      # randomly chosen integers\n",
    "with open('ptb_data/train.txt') as fh:\n",
    "    for il, line in enumerate(fh):\n",
    "        if il in print_lines:\n",
    "            print('Line %i:\\n\"%s\"\\n' %(il, line.strip('\\n') + '<eos>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the size of the splits\n",
    "\n",
    "Here we count the number of words in each of the splits of the training data. For that puropose we define a function, which performs the word counting for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(fname):\n",
    "    tmp = []\n",
    "    with open(fname) as fh:\n",
    "        for line in fh:\n",
    "            tmp2 = line.strip().split() + ['<eos>']\n",
    "            for el in tmp2:\n",
    "                tmp.append(line)\n",
    "    return len(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily determine the number of words in each of the splits of the PTB data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data contains: 929589 words\n",
      "The validation data contains: 73760 words\n",
      "The test data contains: 82430 words\n"
     ]
    }
   ],
   "source": [
    "print('The training data contains:', count_words('ptb_data/train.txt'), 'words')\n",
    "print('The validation data contains:', count_words('ptb_data/valid.txt'), 'words')\n",
    "print('The test data contains:', count_words('ptb_data/test.txt'), 'words')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a dictionary\n",
    "\n",
    "Here we take the example code from https://github.com/pytorch/examples/blob/main/word_language_model/data.py as our data loading routine as it implements everything we need. It includes a dictionary of the words in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data\n",
    "corpus = data.Corpus('ptb_data')\n",
    "len(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are in total 10000 unique words in the dataset. The `Corpus` class contains a dictionary as class attribute, which in turn contains the assignment of an unique integer label to each unique word. As an illustration we print every 1000th word in the dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aer', 'dec.', 'polled', 'furniture', 'sort', 'root', 'geneva', 'tale', 'interpreted', 'gte']\n"
     ]
    }
   ],
   "source": [
    "words = corpus.dictionary.idx2word[::1000]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore the `Corpus` class contains also a lookup table of which word corresponds to which integer label. We illustrate this by printing the integers corresponding ot the words in the variable `words` assigned above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000]\n"
     ]
    }
   ],
   "source": [
    "tmpstr = []\n",
    "for word in words:\n",
    "    tmpstr.append(corpus.dictionary.word2idx[word])\n",
    "print(tmpstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these preparations we are ready to embark on the task of training a Elman RNN on the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
