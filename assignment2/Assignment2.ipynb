{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40edb3ad",
   "metadata": {},
   "source": [
    "# Assignment 2 -- Deep Learning PhD course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f38fa0",
   "metadata": {},
   "source": [
    "We first prepare the playground for this report and import some packages and detect if there is a CUDA device in the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac6ab3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6a0fa",
   "metadata": {},
   "source": [
    "Here are two separate files which contain some useful functions for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48847e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_handling as dh\n",
    "import my_nn_pytorch as mnn\n",
    "import my_plot_functions as mpf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d46e59",
   "metadata": {},
   "source": [
    "# 1 Classification of hand-written digits using a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd14c45b",
   "metadata": {},
   "source": [
    "We first define the hyper parameters, which we are going to use in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adac185a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 64         # batch size during training\n",
    "batch_size_test = 1000       # batch size for the test data\n",
    "lr_sgd = 1e-1                 # learning rate for Stochastic Gradient Descent (SGD)\n",
    "nepochs = 10                  # number of epochs to run the training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3877",
   "metadata": {},
   "source": [
    "The rational behind the choice of the parameters is the following:\n",
    "1. ``batch_size_train``: we choose it small to avoid overfitting of the data even if it is computationally less efficient\n",
    "2. ``batch_size_test``: we choose it large, since my GPU can handle it and I think that the evaluation should go faster if we run it all at once\n",
    "3. ``lr_sgd``: I have observed that with this learning rate the training goes relatively fast and gives still good final accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train, dataloader_test = dh.init_MNIST(batch_size_train, batch_size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbf60a",
   "metadata": {},
   "source": [
    "## 1.1 Fully connected neural network\n",
    "\n",
    "We have constructed a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4791ec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Shape of X for train data [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
      "Shape of y for train data:  torch.Size([64]) torch.int64\n",
      "Shape of X for test data [N, C, H, W]:  torch.Size([1000, 1, 28, 28])\n",
      "Shape of y for test data:  torch.Size([1000]) torch.int64\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=98, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=98, out_features=98, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=98, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              0\n",
      "! ITERATION:          0\n",
      "! COST:           2.323\n",
      "! ACCURACY:       11.6%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              0\n",
      "! ITERATION:          0\n",
      "! COST:           2.321\n",
      "! ACCURACY:       11.8%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              1\n",
      "! ITERATION:        938\n",
      "! COST:           0.290\n",
      "! ACCURACY:       91.4%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              1\n",
      "! ITERATION:        938\n",
      "! COST:           0.295\n",
      "! ACCURACY:       91.2%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              2\n",
      "! ITERATION:       1876\n",
      "! COST:           0.169\n",
      "! ACCURACY:       95.0%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              2\n",
      "! ITERATION:       1876\n",
      "! COST:           0.183\n",
      "! ACCURACY:       94.5%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              3\n",
      "! ITERATION:       2814\n",
      "! COST:           0.116\n",
      "! ACCURACY:       96.5%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              3\n",
      "! ITERATION:       2814\n",
      "! COST:           0.140\n",
      "! ACCURACY:       95.8%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              4\n",
      "! ITERATION:       3752\n",
      "! COST:           0.093\n",
      "! ACCURACY:       97.1%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              4\n",
      "! ITERATION:       3752\n",
      "! COST:           0.125\n",
      "! ACCURACY:       96.3%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              5\n",
      "! ITERATION:       4690\n",
      "! COST:           0.079\n",
      "! ACCURACY:       97.5%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              5\n",
      "! ITERATION:       4690\n",
      "! COST:           0.119\n",
      "! ACCURACY:       96.7%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              6\n",
      "! ITERATION:       5628\n",
      "! COST:           0.067\n",
      "! ACCURACY:       97.9%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              6\n",
      "! ITERATION:       5628\n",
      "! COST:           0.116\n",
      "! ACCURACY:       96.7%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              7\n",
      "! ITERATION:       6566\n",
      "! COST:           0.066\n",
      "! ACCURACY:       97.9%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              7\n",
      "! ITERATION:       6566\n",
      "! COST:           0.122\n",
      "! ACCURACY:       96.7%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              8\n",
      "! ITERATION:       7504\n",
      "! COST:           0.065\n",
      "! ACCURACY:       98.0%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              8\n",
      "! ITERATION:       7504\n",
      "! COST:           0.126\n",
      "! ACCURACY:       96.6%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TRAIN          !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              9\n",
      "! ITERATION:       8442\n",
      "! COST:           0.057\n",
      "! ACCURACY:       98.2%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "!        TEST           !\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "! EPOCH:              9\n",
      "! ITERATION:       8442\n",
      "! COST:           0.126\n",
      "! ACCURACY:       96.8%\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ex11_fc_pytorch as fcp\n",
    "fname = fcp.params2fname(nepochs, lr_sgd, batch_size_train, )\n",
    "try:\n",
    "    mynn = mnn.load_nn(fname)\n",
    "except FileNotFoundError:\n",
    "    model = fcp.NeuralNetwork()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_sgd)\n",
    "    mynn = mnn.MyNeuralNetwork(model, loss_fn, optimizer, dataloader_train, dataloader_test, device=device)\n",
    "    mynn.train(nepochs=nepochs)\n",
    "    mynn.to_disk(fcp.params2fname(nepochs, lr_sgd, batch_size_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, axins = mpf.plot_acc_cost(mynn.perflog2pandas(), len(mynn.dataloader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynn.get_total_train_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7698f48",
   "metadata": {},
   "source": [
    "## 1.2 Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da091d4",
   "metadata": {},
   "source": [
    "We build the following convolutional neural network:\n",
    "\n",
    "| Layer | Function              | More detailed description                                | Output size | Number of parameters            |\n",
    "|-------|-----------------------|----------------------------------------------------------|-------------|---------------------------------|\n",
    "| 0     | Input                 | 28x28 px grey scale images                               | 1x28x28     | 0                               |\n",
    "| 1     | Convolution           | 8 times 3x3x1 convolutions with stride 1 and padding 1   | 8x28x28     | (3\\*3\\*1+1)\\*8 = 80      |\n",
    "| 2     | ReLU                  | Non-linearity                                            | 8x28x28     | 0                               |\n",
    "| 3     | Max Pooling           | 2x2 max pooling with stride 2                            | 8x14x14     | 0                               |\n",
    "| 4     | Convolution           | 16 times 3x3x8 convolutions with stride 1 and padding 1  | 16x14x14    | (3\\*3\\*8+1\\*16 = 1168   |\n",
    "| 5     | ReLU                  | Non-linearity                                            | 16x14x14    | 0                               |\n",
    "| 6     | Max Pooling           | 2x2 max pooling with stride 2                            | 16x7x7      | 0                               |\n",
    "| 7     | Convolution           | 32 times 3x3x16 convolutions with stride 1 and padding 1 | 32x7x7      | (3\\*3\\*16+1\\*32 = 4640  |\n",
    "| 8     | ReLU                  | Non-linearity                                            | 32x7x7      | 0                               |\n",
    "| 9     | Fully Connected       | 10 fully connected layer                                 | 10          | (32\\*7\\*7+1)\\*10 = 15690 |\n",
    "| 10    | Softmax               | Softmax layer                                            | 10          | 0                               |\n",
    "| 11    | Classification Output | Crossentropy with 10 classes                             | 1           | 0                               |\n",
    "\n",
    "The number of learnable parameters of the convolutional and fully connected layers can be computed as follows:\n",
    "1. For a 3x3 convolution with stride 1 and padding 1 the lateral size of the images does not change. A single 3x3 convolution has 3\\*3+1 learnable parameters (the weights of each pixel plus an additional bias). If we carry out $m$ of those in one layer, the number of weights becomes (3\\*3+1)\\*$m$. And if the input data to the layer was of dimension $l$ images, the number of parameters becomes (3\\*3*$l$+1)\\*$m$. This is the formula we have used to compute the number of learnable parameters.\n",
    "2. A fully connected layer has ($n$+1)\\*$m$ weights, where $n$ is the number of inputs and $m$ the number of outputs.\n",
    "\n",
    "Adding the number of learnable parameters in the table, we find for the convolutional neural network we have built here a total of 80 + 1168 + 4640 + 15690 = 21578 learnable parameters. This is in contrast to the total number of weights in our fully connected network:\n",
    "\n",
    "(28\\*28+1)\\*98 + (98+1)\\*98 + (98+1)\\*10 + (10+1)\\*10 = 87732\n",
    "\n",
    "We see that the convolutional network has only about one quarter of the number of parameters of the fully connected network, yet we observe better performance as we will see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ex12_convnn_pytorch as cnnp\n",
    "fname = cnnp.params2fname(nepochs, lr_sgd, batch_size_train, )\n",
    "try:\n",
    "    mynn = mnn.load_nn(fname)\n",
    "except FileNotFoundError:\n",
    "    model = cnnp.NeuralNetwork()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_sgd)\n",
    "    mynn = mnn.MyNeuralNetwork(model, loss_fn, optimizer, dataloader_train, dataloader_test, device=device)\n",
    "    mynn.train(nepochs=nepochs)\n",
    "    mynn.to_disk(cnnp.params2fname(nepochs, lr_sgd, batch_size_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8900e4",
   "metadata": {},
   "source": [
    "Here we plot the performance data of the convolutional network. We see that it reaches above 98% accuracy after about 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ab130",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, axins = mpf.plot_acc_cost(mynn.perflog2pandas(), len(mynn.dataloader_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627b33d9",
   "metadata": {},
   "source": [
    "The final accuracy of our convolutional network on the test data after 10 epochs is 98.7 % with a value of the cost function of 0.045. This performance is somewhat smaller than the performance of the network on the training data, which suggets, that we might have a slight overfitting of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b34258",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynn.print_epoch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df44ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynn.get_total_train_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0fae3",
   "metadata": {},
   "source": [
    "## 1.3 Convolutional Neural Network with swapped order of activation function and Max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c775ea",
   "metadata": {},
   "source": [
    "### 1.3.1 Swapping the order of ReLU and max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6cab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ex13_convnn_swaporder-relu_pytorch as cnnsr\n",
    "fname = cnnsr.params2fname(nepochs, lr_sgd, batch_size_train, )\n",
    "try:\n",
    "    mynn = mnn.load_nn(fname)\n",
    "except FileNotFoundError:\n",
    "    model = cnnsr.NeuralNetwork()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_sgd)\n",
    "    mynn = mnn.MyNeuralNetwork(model, loss_fn, optimizer, dataloader_train, dataloader_test, device=device)\n",
    "    mynn.train(nepochs=nepochs)\n",
    "    mynn.to_disk(cnnsr.params2fname(nepochs, lr_sgd, batch_size_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78497fe",
   "metadata": {},
   "source": [
    "Here we plot the performance data of the convolutional network. We see that it reaches above 98% accuracy after about 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs, axins = mpf.plot_acc_cost(mynn.perflog2pandas(), len(mynn.dataloader_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bda16d",
   "metadata": {},
   "source": [
    "The final accuracy of our convolutional network on the test data after 10 epochs is 98.7 % with a value of the cost function of 0.045. This performance is a little worse than the performance of the network on the training data, which could sugget that we have a slightly overfitted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36797070",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynn.print_epoch_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mynn.get_total_train_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08c000",
   "metadata": {},
   "source": [
    "### 1.3.2 Swapping the order of tanh activation and max pooling\n",
    "\n",
    "Here we repeat the procedure for the tanh activation function. First up we built a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98009bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ex13_convnn_tanh_pytorch as cnnsr\n",
    "fname = cnnsr.params2fname(nepochs, lr_sgd, batch_size_train, )\n",
    "try:\n",
    "    mynn = mnn.load_nn(fname)\n",
    "except FileNotFoundError:\n",
    "    model = cnnsr.NeuralNetwork()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_sgd)\n",
    "    mynn = mnn.MyNeuralNetwork(model, loss_fn, optimizer, dataloader_train, dataloader_test, device=device)\n",
    "    mynn.train(nepochs=nepochs)\n",
    "    mynn.to_disk(cnnsr.params2fname(nepochs, lr_sgd, batch_size_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd504eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba487056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
